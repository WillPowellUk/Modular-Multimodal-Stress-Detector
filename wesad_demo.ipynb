{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Modular Multimodal Data Fusion ML Pipeline for stress detection for the WESAD Database\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started:\n",
    "First, download necessary packages, if you are using a venv such as Conda, activate this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Installation\n",
    "If you are on Linux, run this cell to download and extract the WESAD dataset automatically, otherwise download manually [here](https://uni-siegen.sciebo.de/s/HGdUkoNlW1Ub0Gx/download) and unzip the `WESAD` file into the `wesad` directory i.e. `wesad/WESAD/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd src/wesad && bash download_database.sh\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This will automatically extract the biosensor data from the WESAD directory into several merged files in `.pkl` format.\n",
    "\n",
    "This will take around 10 minutes depending on the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.wesad.data_preprocessing import WESADDataPreprocessor\n",
    "\n",
    "preprocessor = WESADDataPreprocessor('src/wesad/WESAD/')\n",
    "preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Preprocessing Steps\n",
    "We will preprocess each signal with their respective preprocessing steps:\n",
    "\n",
    "### Chest Signals\n",
    "\n",
    "#### ECG\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.7 Hz and 3.7 Hz.\n",
    "\n",
    "#### EMG\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth lowpass filter of order 3 with cutoff frequency 0.5 Hz.\n",
    "\n",
    "#### EDA\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth lowpass filter of order 2 with cutoff frequency 5 Hz.\n",
    "\n",
    "#### TEMP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "\n",
    "#### RESP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.1 Hz and 0.35 Hz.\n",
    "\n",
    "#### ACC\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 31 and order 5.\n",
    "\n",
    "### Wrist Signals\n",
    "\n",
    "#### BVP\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.7 Hz and 3.7 Hz.\n",
    "\n",
    "#### TEMP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "\n",
    "#### ACC\n",
    "- **Filtering**: Finite Impulse Response (FIR) filter with a length of 64 with a cut-off frequency of 0.4 Hz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config_files\n",
    "CHEST_CONFIG = 'config_files/dataset/wesad_chest_configuration.json'\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.preprocessing import SignalPreprocessor\n",
    "\n",
    "# preprocess the chest data\n",
    "signal_preprocessor = SignalPreprocessor('src/wesad/WESAD/raw/merged_chest.pkl', 'src/wesad/WESAD/cleaned/chest_preprocessed.pkl', CHEST_CONFIG)\n",
    "signal_preprocessor.preprocess_signals()\n",
    "\n",
    "# preprocess the wrist data\n",
    "signal_preprocessor = SignalPreprocessor('src/wesad/WESAD/raw/merged_wrist.pkl', 'src/wesad/WESAD/cleaned/wrist_preprocessed.pkl', WRIST_CONFIG, wrist=True)\n",
    "signal_preprocessor.preprocess_signals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation and Splitting\n",
    "Data augmentation will take the form of a sliding window. Once the data is augmented, each sample will then be split into smaller segments if it is not used in the autoregression case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import DataAugmenter\n",
    "\n",
    "AUTOREGRESSIVE = True\n",
    "\n",
    "if AUTOREGRESSIVE:\n",
    "    WINDOW_LENGTH = 10\n",
    "    SLIDING_LENGTH = 2 # this will create 5 segments per 10 seconds since 10/2 = 5 with 4:1 ratio of synthetic to real samples\n",
    "    SPLIT_LENGTH = WINDOW_LENGTH # this will not sub-split the data\n",
    "else: \n",
    "    WINDOW_LENGTH = 60\n",
    "    SLIDING_LENGTH = 5 # this will create 12 segments per minute since 60/5 = 12 with 11:1 ratio of synthetic to real samples\n",
    "    SPLIT_LENGTH = 10 # this will sub-split each 60 second segments into 6 x 10 second segments\n",
    "    WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "\n",
    "wrist_augmenter = DataAugmenter('src/wesad/WESAD/cleaned/wrist_preprocessed.pkl', WRIST_CONFIG) \n",
    "batches = wrist_augmenter.augment_data(WINDOW_LENGTH, SLIDING_LENGTH)\n",
    "wrist_splitted_segments = wrist_augmenter.split_segments(batches, WINDOW_LENGTH//SPLIT_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Machine Learning\n",
    "\n",
    "The manual feature extraction derives features in the time, frequency and non-linear domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.feature_extraction import ManualFE\n",
    "\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "\n",
    "manual_fe = ManualFE(wrist_splitted_segments, WRIST_FE, WRIST_CONFIG)\n",
    "manual_fe.extract_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LOSOCV Datasets\n",
    "\n",
    "Now, using the preprocessed `.pkl` files we will make it into a dataloader with LOSOCV (Leave one subject out cross validation). The data augmented samples will be used in the training set but ignored in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import LOSOCVDataLoader\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "# WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/test203/wrist_manual_fe_{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s.hdf5'\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "losocv_loader = LOSOCVDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "\n",
    "# Prepare the datasets\n",
    "DATASETS_PATH = losocv_loader.prepare_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate Models with LOSOCV\n",
    "\n",
    "Now we can use the prepared datasets and form dataloaders which will then be used to perform LOSOCV on the models. Using the config file we can set the models that we want to test and their corresponding hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import LOSOCVDataLoader\n",
    "from src.ml_pipeline.train import TraditionalMLTrainer\n",
    "from src.utils import save_var\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "\n",
    "# Load tradtional model config\n",
    "losocv_loader = LOSOCVDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "dataloaders = losocv_loader.get_data_loaders(DATASETS_PATH)\n",
    "TRADTIONAL_ML_CONFIG = 'config_files/model_training/traditional/traditional_models.json'\n",
    "\n",
    "results = []\n",
    "for i, (subject_id, loaders) in enumerate(dataloaders.items()):\n",
    "    train_loader = loaders['train']\n",
    "    val_loader = loaders['val']\n",
    "    \n",
    "    print(f'\\nFold {i}')\n",
    "    print(f'Train: {len(train_loader.dataset)}')\n",
    "    print(f'Val: {len(val_loader.dataset)}')\n",
    "    print()\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = TraditionalMLTrainer(TRADTIONAL_ML_CONFIG, train_loader, val_loader)\n",
    "\n",
    "    # trained_models = trainer.tune_hyperparameters(n_jobs=4, cv=None, verbose=2)\n",
    "    trained_models = trainer.train()\n",
    "\n",
    "    result = trainer.validate(trained_models)\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "\n",
    "# save the results to pkl\n",
    "save_var(results, 'src/wesad/WESAD/results/traditional_models/wrist_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.analysis import ModelResultsAnalysis\n",
    "from src.utils import load_var\n",
    "\n",
    "results = load_var('src/wesad/WESAD/results/traditional_models/wrist_results.pkl')\n",
    "\n",
    "analysis = ModelResultsAnalysis(results)\n",
    "analysis.analyze_collective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention Network Alongside Manual Feature Extraction\n",
    "This network employs self-attention networks for intra-modality feature extraction before applying late fusion between modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LOSOCV Datasets on a Per Sensor Basis\n",
    "\n",
    "Now, using the preprocessed `.pkl` files we will make it into a dataloader with LOSOCV (Leave one subject out cross validation) on a per sensor basis. The data augmented samples will be used in the training set but ignored in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import LOSOCVSensorDataLoader\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "dataloader_params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "losocv_loader = LOSOCVSensorDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "\n",
    "# Prepare the datasets\n",
    "DATASETS_PATH = losocv_loader.prepare_datasets(f'src/wesad/WESAD/datasets/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate Models with LOSOCV\n",
    "\n",
    "Now we can use the prepared datasets and form dataloaders which will then be used to perform LOSOCV on the models. Using the config file we can set the models that we want to test and their corresponding hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.train import PyTorchTrainer\n",
    "from src.ml_pipeline.models.attention_models import ModularModalityFusionNet\n",
    "from src.ml_pipeline.data_loader import LOSOCVSensorDataLoader\n",
    "from src.ml_pipeline.utils import get_active_key, get_key, load_json, copy_json, get_values\n",
    "from src.utils import save_var\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "\n",
    "DATASETS_PATH = f'src/wesad/WESAD/datasets/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/losocv_datasets.pkl'\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s_mini/wrist_features.hdf5'\n",
    "SAN_MODEL_CONFIG = 'config_files/model_training/deep/modular_modality_fusion_net_config.json'\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': get_values(SAN_MODEL_CONFIG, 'batch_size'),\n",
    "    'shuffle': True,\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "\n",
    "# Load Dataloaders for LOSOCV\n",
    "losocv_loader = LOSOCVSensorDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "dataloaders, input_dims = losocv_loader.get_data_loaders(DATASETS_PATH)\n",
    "\n",
    "# Load Model Parameters\n",
    "model_config = load_json(SAN_MODEL_CONFIG)\n",
    "model_config = {\n",
    "    **model_config,\n",
    "    'input_dims': input_dims\n",
    "}\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "results = []\n",
    "for i, (subject_id, loaders) in enumerate(dataloaders.items()):\n",
    "    train_loader = loaders['train']\n",
    "    val_loader = loaders['val']\n",
    "    \n",
    "    print(f'\\nSubject: {subject_id}')\n",
    "    print(f'Train: {len(train_loader.dataset)}')\n",
    "    print(f'Val: {len(val_loader.dataset)}')\n",
    "    print()\n",
    "\n",
    "    # Initialize model\n",
    "    model = ModularModalityFusionNet(**model_config)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = PyTorchTrainer(model, train_loader, val_loader, SAN_MODEL_CONFIG, device)\n",
    "    trainer.save_path = trainer.save_path.format(fold=f'subject_{subject_id}')\n",
    "    if i == 0:\n",
    "        trainer.print_model_summary()\n",
    "    trained_model_ckpt = trainer.train()\n",
    "    print(f'Model checkpoint saved to: {trained_model_ckpt}\\n')\n",
    "\n",
    "    result = trainer.validate(trained_model_ckpt)\n",
    "    results.append(result)\n",
    "    break\n",
    "\n",
    "# save the results to pkl\n",
    "current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "save_path = f'src/wesad/WESAD/results/san/wrist_results/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/{current_time}/generalized'\n",
    "save_var(results, f'{save_path}/results.pkl', 'Results')\n",
    "copy_json(SAN_MODEL_CONFIG, f'{save_path}/config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.analysis import ModelResultsAnalysis\n",
    "from src.utils import load_var\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "\n",
    "# results_path = 'src/wesad/WESAD/results/san/wrist_results/60s_5s_10s/2024_06_20_14_55_01/.pkl'\n",
    "results_path = f'{save_path}/results.pkl'\n",
    "results = load_var(results_path)\n",
    "\n",
    "analysis = ModelResultsAnalysis(results)\n",
    "analysis.analyze_collective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losocv_datasets = {2: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_2.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_2.hdf5'}, 3: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_3.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_3.hdf5'}, 4: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_4.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_4.hdf5'}, 5: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_5.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_5.hdf5'}, 6: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_6.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_6.hdf5'}, 7: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_7.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_7.hdf5'}, 8: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_8.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_8.hdf5'}, 9: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_9.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_9.hdf5'}, 10: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_10.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_10.hdf5'}, 11: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_11.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_11.hdf5'}, 13: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_13.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_13.hdf5'}, 14: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_14.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_14.hdf5'}, 15: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_15.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_15.hdf5'}, 16: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_16.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_16.hdf5'}, 17: {'train': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/train_17.hdf5', 'val': 'src/wesad/WESAD/datasets/10s_2s_10s/losocv/val_17.hdf5'}}\n",
    "\n",
    "# save the updated losocv_datasets to the same file\n",
    "with open('src/wesad/WESAD/datasets/10s_2s_10s/losocv_datasets.pkl', 'wb') as f:\n",
    "    pickle.dump(losocv_datasets, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Cross Validation Dataloader for Personalization\n",
    "\n",
    "First we must prepare a new dataloader which exclusively contains one subject's personalized data that is used to cross validate the personalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import PersonalSensorDataLoader\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "dataloader_params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "\n",
    "SUBJECT_ID = 2\n",
    "personal_loader = PersonalSensorDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "\n",
    "# Prepare the datasets\n",
    "DATASETS_PATH = personal_loader.prepare_datasets(f'src/wesad/WESAD/datasets/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s', SUBJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Personalization via Transfer Learning\n",
    "\n",
    "This will then be used to fine tune the model with the new multiheaded attention blocks architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.train import PyTorchTrainer\n",
    "from src.ml_pipeline.models.attention_models import PersonalizedModalityFusionNet, ModularModalityFusionNet\n",
    "from src.ml_pipeline.data_loader import PersonalSensorDataLoader\n",
    "from src.ml_pipeline.utils import get_active_key, load_json, copy_json, get_values\n",
    "from src.utils import save_var\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "\n",
    "SUBJECT_ID = 2\n",
    "\n",
    "DATASETS_PATH = f'src/wesad/WESAD/datasets/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/subject_{SUBJECT_ID}/personal_dataset.pkl'\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "PERSONALIZED_SAN_MODEL_CONFIG = 'config_files/model_training/deep/personalized_modality_fusion_net_config.json'\n",
    "MFN_CKPT_PATH = 'src/wesad/WESAD/ckpts/san/wrist_manual_fe/60s_5s_10s/generalized/subject_2/checkpoint_5.pth'\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': get_values(PERSONALIZED_SAN_MODEL_CONFIG, 'batch_size'),\n",
    "    'shuffle': True,\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "\n",
    "# Load Dataloaders for LOSOCV\n",
    "personal_loader = PersonalSensorDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "dataloaders, input_dims = personal_loader.get_data_loaders(DATASETS_PATH)\n",
    "\n",
    "# Load Model Parameters\n",
    "model_config = load_json(PERSONALIZED_SAN_MODEL_CONFIG)\n",
    "model_config = {\n",
    "    **model_config,\n",
    "    'input_dims': input_dims\n",
    "}\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "results = []\n",
    "for i, loaders in enumerate(dataloaders):\n",
    "    train_loader = loaders['train']\n",
    "    val_loader = loaders['val']    \n",
    "    print(f'\\nFold: {i}')\n",
    "    print(f'Train: {len(train_loader.dataset)}')\n",
    "    print(f'Val: {len(val_loader.dataset)}')\n",
    "    print()\n",
    "\n",
    "    # Initialize model\n",
    "    model = PersonalizedModalityFusionNet(MFN_CKPT_PATH, ModularModalityFusionNet, **model_config)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = PyTorchTrainer(model, train_loader, val_loader, PERSONALIZED_SAN_MODEL_CONFIG, device)\n",
    "    trainer.save_path = trainer.save_path.format(fold=f'fold_{i}')\n",
    "    if i == 0:\n",
    "        trainer.print_model_summary()\n",
    "    trained_model_ckpt = trainer.train()\n",
    "    print(f'Model saved at: {trained_model_ckpt}')\n",
    "\n",
    "    result = trainer.validate(trained_model_ckpt)\n",
    "    results.append(result)\n",
    "\n",
    "# save the results to pkl\n",
    "current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "save_path = f'src/wesad/WESAD/results/san/wrist_results/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/{current_time}/personalized'\n",
    "save_var(results, f'{save_path}/results.pkl', 'results')\n",
    "copy_json(PERSONALIZED_SAN_MODEL_CONFIG, f'{save_path}/config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.analysis import ModelResultsAnalysis\n",
    "from src.utils import load_var\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "\n",
    "results_path = f'src/wesad/WESAD/results/san/wrist_results/60s_5s_10s/2024_06_22_14_20_25/personalized/results.pkl'\n",
    "results = load_var(results_path)\n",
    "\n",
    "analysis = ModelResultsAnalysis(results)\n",
    "analysis.analyze_collective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional Cross-and Self-modal Attention (BCSA) \n",
    "\n",
    "This model now integrates cross attention into the self-attention network for inter-modality and intra-modality feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate Model with LOSOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.train import PyTorchTrainer\n",
    "from src.ml_pipeline.models.attention_models import ModularBCSA\n",
    "from src.ml_pipeline.data_loader import LOSOCVSensorDataLoader\n",
    "from src.ml_pipeline.utils import load_json, copy_json, get_values\n",
    "from src.utils import save_var\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will subsplit each 60 second segments into 6 x 10 second segments\n",
    "\n",
    "# DATASETS_PATH = f'src/wesad/WESAD/datasets/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}_mini/wrist_manual_fe_{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}.hdf5'\n",
    "DATASETS_PATH = f'src/wesad/WESAD/datasets/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/losocv_datasets.pkl'\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s_mini/wrist_features.hdf5'\n",
    "BCSA_MODEL_CONFIG = 'config_files/model_training/deep/bsca_config.json'\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': get_values(BCSA_MODEL_CONFIG, 'batch_size'),\n",
    "    'shuffle': True,\n",
    "}\n",
    "\n",
    "# Load Dataloaders for LOSOCV\n",
    "losocv_loader = LOSOCVSensorDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "dataloaders, input_dims = losocv_loader.get_data_loaders(DATASETS_PATH)\n",
    "\n",
    "# Load Model Parameters\n",
    "model_config = load_json(BCSA_MODEL_CONFIG)\n",
    "model_config = {\n",
    "    **model_config,\n",
    "    'input_dims': input_dims\n",
    "}\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "results = []\n",
    "for i, (subject_id, loaders) in enumerate(dataloaders.items()):\n",
    "    train_loader = loaders['train']\n",
    "    val_loader = loaders['val']\n",
    "    \n",
    "    print(f'\\nSubject: {subject_id}')\n",
    "    print(f'Train: {len(train_loader.dataset)}')\n",
    "    print(f'Val: {len(val_loader.dataset)}')\n",
    "    print()\n",
    "\n",
    "    # Initialize model\n",
    "    model = ModularBCSA(**model_config)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = PyTorchTrainer(model, train_loader, val_loader, BCSA_MODEL_CONFIG, device)\n",
    "    trainer.save_path = trainer.save_path.format(fold=f'subject_{subject_id}')\n",
    "    \n",
    "    # if i == 0:\n",
    "    #     trainer.print_model_summary()\n",
    "\n",
    "    trained_model_ckpt = trainer.train()\n",
    "    print(f'Model checkpoint saved to: {trained_model_ckpt}\\n')\n",
    "\n",
    "    result = trainer.validate(trained_model_ckpt)\n",
    "    results.append(result)\n",
    "    break\n",
    "\n",
    "# save the results to pkl\n",
    "current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "save_path = f'src/wesad/WESAD/results/bcsa/wrist_results/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/{current_time}/generalized'\n",
    "save_var(results, f'{save_path}/results.pkl', 'Results')\n",
    "copy_json(BCSA_MODEL_CONFIG, f'{save_path}/config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.analysis import ModelResultsAnalysis\n",
    "from src.utils import load_var\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "\n",
    "# results_path = f'{save_path}/results.pkl'\n",
    "# results_path = 'src/wesad/WESAD/results/bcsa/wrist_results/60s_5s_10s/2024_06_21_15_50_27/generalized/results.pkl'\n",
    "results_path = 'src/wesad/WESAD/results/bcsa/wrist_results/60s_5s_10s/2024_06_27_17_23_40/generalized/results.pkl'\n",
    "results = load_var(results_path)\n",
    "\n",
    "analysis = ModelResultsAnalysis(results)\n",
    "analysis.analyze_collective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modular Autoregressive Co-Attention Network (MARCONet)  \n",
    "\n",
    "This model now integrates modularity to the Self and Cross Attention Network for inter-modality and intra-modality feature extraction using both early fusion of pairwise modalities and late fusion of the ensemble learning branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LOSOCV Datasets on a Per Sensor Basis\n",
    "\n",
    "Now, using the preprocessed `.pkl` files we will make it into a dataloader with LOSOCV (Leave one subject out cross validation) on a per sensor basis. The data augmented samples will be used in the training set but ignored in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import LOSOCVSensorDataLoader\n",
    "\n",
    "WINDOW_LENGTH = 10\n",
    "SLIDING_LENGTH = 2 # this will create 5 segments per 10 seconds since 10/2 = 5 with 4:1 ratio of synthetic to real samples\n",
    "SPLIT_LENGTH = WINDOW_LENGTH # this will not sub-split the data\n",
    "\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "dataloader_params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "losocv_loader = LOSOCVSensorDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "\n",
    "# Prepare the datasets\n",
    "DATASETS_PATH = losocv_loader.prepare_datasets(f'src/wesad/WESAD/datasets/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate Models with LOSOCV\n",
    "\n",
    "Now we can use the prepared datasets and form dataloaders which will then be used to perform LOSOCV on the models. Using the config file we can set the models that we want to test and their corresponding hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Subject: 2\n",
      "Train: 12762\n",
      "Val: 174\n",
      "\n",
      "Storing tensorboard log to: src/wesad/WESAD/ckpts/co_attention/wrist_manual_fe/10s_2s_10s/generalized/subject_2/tensorboard\n",
      "Open TensorBoard in your browser to monitor training progress.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "I0628 19:08:46.696333 137365192435264 plugin.py:429] Monitor runs begin\n",
      "TensorBoard 2.17.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "Epoch 1/1:  12%|█▏        | 1486/12762 [03:13<24:27,  7.68it/s, loss=0.00229] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_path \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39msave_path\u001b[38;5;241m.\u001b[39mformat(fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# if i == 0:\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#     trainer.print_model_summary()\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m trained_model_ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel checkpoint saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrained_model_ckpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mvalidate(trained_model_ckpt)\n",
      "File \u001b[0;32m~/Dev/Imperial FYP/ Modular-Multimodal-Stress-Detector/src/ml_pipeline/train/pytorch_trainer.py:64\u001b[0m, in \u001b[0;36mPyTorchTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbvp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader\u001b[38;5;241m.\u001b[39mbatch_size:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch_y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     65\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs)\n\u001b[1;32m     66\u001b[0m one_hot_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(labels \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/envs/ML_Dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML_Dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/Imperial FYP/ Modular-Multimodal-Stress-Detector/src/ml_pipeline/models/attention_models/co_attention_models.py:163\u001b[0m, in \u001b[0;36mMARCONet.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m modality1 \u001b[38;5;241m!=\u001b[39m modality2:\n\u001b[1;32m    162\u001b[0m             ca_block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attention_blocks[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodality1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_to_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodality2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][i]\n\u001b[0;32m--> 163\u001b[0m             modality_features[modality1] \u001b[38;5;241m=\u001b[39m \u001b[43mca_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodality_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodality1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodality_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodality2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modality, net \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodalities\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    166\u001b[0m     sa_block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attention_blocks[modality][i]\n",
      "File \u001b[0;32m~/anaconda3/envs/ML_Dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML_Dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/Imperial FYP/ Modular-Multimodal-Stress-Detector/src/ml_pipeline/models/attention_models/attention_mechansims.py:171\u001b[0m, in \u001b[0;36mCachedSlidingCrossAttentionEncoder.forward\u001b[0;34m(self, query, key_value, use_cache)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     keys, values \u001b[38;5;241m=\u001b[39m key_value, key_value\n\u001b[0;32m--> 171\u001b[0m query, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Update cache\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/ML_Dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML_Dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML_Dev/lib/python3.12/site-packages/torch/nn/modules/activation.py:1266\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1253\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1264\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1266\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/anaconda3/envs/ML_Dev/lib/python3.12/site-packages/torch/nn/functional.py:5462\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_weights:\n\u001b[1;32m   5461\u001b[0m     B, Nt, E \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m-> 5462\u001b[0m     q_scaled \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mE\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   5464\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_causal \u001b[38;5;129;01mand\u001b[39;00m attn_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFIXME: is_causal not implemented for need_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attn_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.ml_pipeline.train import PyTorchTrainer\n",
    "from src.ml_pipeline.models.attention_models import MARCONet\n",
    "from src.ml_pipeline.data_loader import LOSOCVSensorDataLoader\n",
    "from src.ml_pipeline.utils import get_active_key, get_key, load_json, copy_json, get_values\n",
    "from src.utils import save_var\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "WINDOW_LENGTH = 10\n",
    "SLIDING_LENGTH = 2 # this will create 5 segments per 10 seconds since 10/2 = 5 with 4:1 ratio of synthetic to real samples\n",
    "SPLIT_LENGTH = WINDOW_LENGTH # this will not sub-split the data\n",
    "\n",
    "DATASETS_PATH = f'src/wesad/WESAD/datasets/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/losocv_datasets.pkl'\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "MARCO_CONFIG = 'config_files/model_training/deep/marco_config.json'\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': get_values(MARCO_CONFIG, 'batch_size'),\n",
    "    'shuffle': False,\n",
    "    'drop_last': True\n",
    "}\n",
    "\n",
    "# Load Dataloaders for LOSOCV\n",
    "losocv_loader = LOSOCVSensorDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "dataloaders, input_dims = losocv_loader.get_data_loaders(DATASETS_PATH)\n",
    "\n",
    "# Load Model Parameters\n",
    "model_config = load_json(MARCO_CONFIG)\n",
    "model_config = {\n",
    "    **model_config,\n",
    "    'input_dims': input_dims\n",
    "}\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "results = []\n",
    "for i, (subject_id, loaders) in enumerate(dataloaders.items()):\n",
    "    train_loader = loaders['train']\n",
    "    val_loader = loaders['val']\n",
    "    \n",
    "    print(f'\\nSubject: {subject_id}')\n",
    "    print(f'Train: {len(train_loader.dataset)}')\n",
    "    print(f'Val: {len(val_loader.dataset)}')\n",
    "    print()\n",
    "\n",
    "    # Initialize model\n",
    "    model = MARCONet(**model_config)\n",
    "\n",
    "    # Initialize trainerself.attention(x, x, x)\n",
    "    trainer = PyTorchTrainer(model, train_loader, val_loader, MARCO_CONFIG, device)\n",
    "    trainer.save_path = trainer.save_path.format(fold=f'subject_{subject_id}')\n",
    "    # if i == 0:\n",
    "    #     trainer.print_model_summary()\n",
    "    trained_model_ckpt = trainer.train()\n",
    "    print(f'Model checkpoint saved to: {trained_model_ckpt}\\n')\n",
    "\n",
    "    result = trainer.validate(trained_model_ckpt)\n",
    "    results.append(result)\n",
    "    break\n",
    "\n",
    "# save the results to pkl\n",
    "current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "save_path = f'src/wesad/WESAD/results/san/wrist_results/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/{current_time}/generalized'\n",
    "save_var(results, f'{save_path}/results.pkl', 'Results')\n",
    "copy_json(MARCO_CONFIG, f'{save_path}/config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable loaded from src/wesad/WESAD/results/san/wrist_results/10s_2s_10s/2024_06_28_11_46_55/generalized/results.pkl\n",
      "MARCONet:\n",
      "  Accuracy: 0.65517\n",
      "  Precision: 0.42925\n",
      "  Recall: 0.65517\n",
      "  F1 Score: 0.51868\n",
      "  Inference Time (ms): 11.02522\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.ml_pipeline.analysis import ModelResultsAnalysis\n",
    "from src.utils import load_var\n",
    "\n",
    "results_path = f'{save_path}/results.pkl'\n",
    "results = load_var(results_path)\n",
    "\n",
    "analysis = ModelResultsAnalysis(results)\n",
    "analysis.analyze_collective()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Dev_C11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
