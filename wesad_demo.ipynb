{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Modular Multimodal Data Fusion ML Pipeline for stress detection for the WESAD Database\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started:\n",
    "First, download necessary packages, if you are using a venv such as Conda, activate this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Installation\n",
    "If you are on Linux, run this cell to download and extract the WESAD dataset automatically, otherwise download manually [here](https://uni-siegen.sciebo.de/s/HGdUkoNlW1Ub0Gx/download) and unzip the `WESAD` file into the `wesad` directory i.e. `wesad/WESAD/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd src/wesad && bash download_database.sh\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This will automatically extract the biosensor data from the WESAD directory into several merged files in `.pkl` format.\n",
    "\n",
    "This will take around 10 minutes depending on the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.wesad.data_preprocessing import WESADDataPreprocessor\n",
    "\n",
    "preprocessor = WESADDataPreprocessor('src/wesad/WESAD/')\n",
    "preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Preprocessing Steps\n",
    "We will preprocess each signal with their respective preprocessing steps:\n",
    "\n",
    "### Chest Signals\n",
    "\n",
    "#### ECG\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.7 Hz and 3.7 Hz.\n",
    "\n",
    "#### EMG\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth lowpass filter of order 3 with cutoff frequency 0.5 Hz.\n",
    "\n",
    "#### EDA\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth lowpass filter of order 2 with cutoff frequency 5 Hz.\n",
    "\n",
    "#### TEMP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "\n",
    "#### RESP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.1 Hz and 0.35 Hz.\n",
    "\n",
    "#### ACC\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 31 and order 5.\n",
    "\n",
    "### Wrist Signals\n",
    "\n",
    "#### BVP\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.7 Hz and 3.7 Hz.\n",
    "\n",
    "#### TEMP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "\n",
    "#### ACC\n",
    "- **Filtering**: Finite Impulse Response (FIR) filter with a length of 64 with a cut-off frequency of 0.4 Hz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config_files\n",
    "CHEST_CONFIG = 'config_files/dataset/wesad_chest_configuration.json'\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.preprocessing import SignalPreprocessor\n",
    "\n",
    "# preprocess the chest data\n",
    "signal_preprocessor = SignalPreprocessor('src/wesad/WESAD/raw/merged_chest.pkl', 'src/wesad/WESAD/cleaned/chest_preprocessed.pkl', CHEST_CONFIG)\n",
    "signal_preprocessor.preprocess_signals()\n",
    "\n",
    "# preprocess the wrist data\n",
    "signal_preprocessor = SignalPreprocessor('src/wesad/WESAD/raw/merged_wrist.pkl', 'src/wesad/WESAD/cleaned/wrist_preprocessed.pkl', WRIST_CONFIG, wrist=True)\n",
    "signal_preprocessor.preprocess_signals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Machine Learning: Manual Feature Extraction\n",
    "\n",
    "During the feature extraction, data is loaded in an augmented manner using a 60-second window with a sliding length of 5 seconds.\n",
    "\n",
    "The manual feature extraction derives the following features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting data...\n",
      "Segmentation complete.\n",
      "Extracting features from batch 1/17202 | ETA: 0.07 seconds\n",
      "Extracting features from batch 101/17202 | ETA: 1009.21 seconds\n",
      "Extracting features from batch 201/17202 | ETA: 946.58 seconds\n",
      "Extracting features from batch 301/17202 | ETA: 941.43 seconds\n",
      "Extracting features from batch 401/17202 | ETA: 919.97 seconds\n",
      "Extracting features from batch 501/17202 | ETA: 955.55 seconds\n",
      "Extracting features from batch 601/17202 | ETA: 954.93 seconds\n",
      "Extracting features from batch 701/17202 | ETA: 943.50 seconds\n",
      "Extracting features from batch 801/17202 | ETA: 937.88 seconds\n",
      "Extracting features from batch 901/17202 | ETA: 925.68 seconds\n",
      "Extracting features from batch 1001/17202 | ETA: 913.96 seconds\n",
      "Extracting features from batch 1101/17202 | ETA: 907.40 seconds\n",
      "Extracting features from batch 1201/17202 | ETA: 898.09 seconds\n",
      "Extracting features from batch 1301/17202 | ETA: 894.05 seconds\n",
      "Extracting features from batch 1401/17202 | ETA: 886.62 seconds\n",
      "Extracting features from batch 1501/17202 | ETA: 878.50 seconds\n",
      "Extracting features from batch 1601/17202 | ETA: 870.13 seconds\n",
      "Extracting features from batch 1701/17202 | ETA: 861.99 seconds\n",
      "Extracting features from batch 1801/17202 | ETA: 853.57 seconds\n",
      "Extracting features from batch 1901/17202 | ETA: 845.70 seconds\n",
      "Extracting features from batch 2001/17202 | ETA: 837.95 seconds\n",
      "Extracting features from batch 2101/17202 | ETA: 830.21 seconds\n",
      "Extracting features from batch 2201/17202 | ETA: 823.37 seconds\n",
      "Extracting features from batch 2301/17202 | ETA: 816.83 seconds\n",
      "Extracting features from batch 2401/17202 | ETA: 810.04 seconds\n",
      "Extracting features from batch 2501/17202 | ETA: 803.36 seconds\n",
      "Extracting features from batch 2601/17202 | ETA: 797.38 seconds\n",
      "Extracting features from batch 2701/17202 | ETA: 791.58 seconds\n",
      "Extracting features from batch 2801/17202 | ETA: 787.70 seconds\n",
      "Extracting features from batch 2901/17202 | ETA: 781.47 seconds\n",
      "Extracting features from batch 3001/17202 | ETA: 775.45 seconds\n",
      "Extracting features from batch 3101/17202 | ETA: 769.09 seconds\n",
      "Extracting features from batch 3201/17202 | ETA: 765.18 seconds\n",
      "Extracting features from batch 3301/17202 | ETA: 759.08 seconds\n",
      "Extracting features from batch 3401/17202 | ETA: 753.29 seconds\n",
      "Extracting features from batch 3501/17202 | ETA: 747.45 seconds\n",
      "Extracting features from batch 3601/17202 | ETA: 741.75 seconds\n",
      "Extracting features from batch 3701/17202 | ETA: 736.23 seconds\n",
      "Extracting features from batch 3801/17202 | ETA: 730.94 seconds\n",
      "Extracting features from batch 3901/17202 | ETA: 725.17 seconds\n",
      "Extracting features from batch 4001/17202 | ETA: 719.25 seconds\n",
      "Extracting features from batch 4101/17202 | ETA: 713.77 seconds\n",
      "Extracting features from batch 4201/17202 | ETA: 707.94 seconds\n",
      "Extracting features from batch 4301/17202 | ETA: 701.94 seconds\n",
      "Extracting features from batch 4401/17202 | ETA: 695.90 seconds\n",
      "Extracting features from batch 4501/17202 | ETA: 689.69 seconds\n",
      "Extracting features from batch 4601/17202 | ETA: 683.64 seconds\n",
      "Extracting features from batch 4701/17202 | ETA: 679.09 seconds\n",
      "Extracting features from batch 4801/17202 | ETA: 673.39 seconds\n",
      "Extracting features from batch 4901/17202 | ETA: 667.41 seconds\n",
      "Extracting features from batch 5001/17202 | ETA: 661.54 seconds\n",
      "Extracting features from batch 5101/17202 | ETA: 655.68 seconds\n",
      "Extracting features from batch 5201/17202 | ETA: 650.05 seconds\n",
      "Extracting features from batch 5301/17202 | ETA: 644.21 seconds\n",
      "Extracting features from batch 5401/17202 | ETA: 638.47 seconds\n",
      "Extracting features from batch 5501/17202 | ETA: 632.86 seconds\n",
      "Extracting features from batch 5601/17202 | ETA: 627.29 seconds\n",
      "Extracting features from batch 5701/17202 | ETA: 621.64 seconds\n",
      "Extracting features from batch 5801/17202 | ETA: 615.90 seconds\n",
      "Extracting features from batch 5901/17202 | ETA: 610.14 seconds\n",
      "Extracting features from batch 6001/17202 | ETA: 604.61 seconds\n",
      "Extracting features from batch 6101/17202 | ETA: 598.89 seconds\n",
      "Extracting features from batch 6201/17202 | ETA: 593.51 seconds\n",
      "Extracting features from batch 6301/17202 | ETA: 587.89 seconds\n",
      "Extracting features from batch 6401/17202 | ETA: 582.32 seconds\n",
      "Extracting features from batch 6501/17202 | ETA: 576.57 seconds\n",
      "Extracting features from batch 6601/17202 | ETA: 571.15 seconds\n",
      "Extracting features from batch 6701/17202 | ETA: 565.62 seconds\n",
      "Extracting features from batch 6801/17202 | ETA: 560.06 seconds\n",
      "Extracting features from batch 6901/17202 | ETA: 554.49 seconds\n",
      "Extracting features from batch 7001/17202 | ETA: 548.92 seconds\n",
      "Extracting features from batch 7101/17202 | ETA: 544.10 seconds\n",
      "Extracting features from batch 7201/17202 | ETA: 538.44 seconds\n",
      "Extracting features from batch 7301/17202 | ETA: 533.04 seconds\n",
      "Extracting features from batch 7401/17202 | ETA: 527.53 seconds\n",
      "Extracting features from batch 7501/17202 | ETA: 522.06 seconds\n",
      "Extracting features from batch 7601/17202 | ETA: 516.51 seconds\n",
      "Extracting features from batch 7701/17202 | ETA: 511.11 seconds\n",
      "Extracting features from batch 7801/17202 | ETA: 505.50 seconds\n",
      "Extracting features from batch 7901/17202 | ETA: 499.97 seconds\n",
      "Extracting features from batch 8001/17202 | ETA: 494.44 seconds\n",
      "Extracting features from batch 8101/17202 | ETA: 489.02 seconds\n",
      "Extracting features from batch 8201/17202 | ETA: 483.54 seconds\n",
      "Extracting features from batch 8301/17202 | ETA: 478.11 seconds\n",
      "Extracting features from batch 8401/17202 | ETA: 472.67 seconds\n",
      "Extracting features from batch 8501/17202 | ETA: 467.17 seconds\n",
      "Extracting features from batch 8601/17202 | ETA: 461.71 seconds\n",
      "Extracting features from batch 8701/17202 | ETA: 456.23 seconds\n",
      "Extracting features from batch 8801/17202 | ETA: 450.75 seconds\n",
      "Extracting features from batch 8901/17202 | ETA: 445.42 seconds\n",
      "Extracting features from batch 9001/17202 | ETA: 439.96 seconds\n",
      "Extracting features from batch 9101/17202 | ETA: 434.56 seconds\n",
      "Extracting features from batch 9201/17202 | ETA: 429.09 seconds\n",
      "Extracting features from batch 9301/17202 | ETA: 423.66 seconds\n",
      "Extracting features from batch 9401/17202 | ETA: 418.27 seconds\n",
      "Extracting features from batch 9501/17202 | ETA: 412.84 seconds\n",
      "Extracting features from batch 9601/17202 | ETA: 407.49 seconds\n",
      "Extracting features from batch 9701/17202 | ETA: 402.05 seconds\n",
      "Extracting features from batch 9801/17202 | ETA: 396.59 seconds\n",
      "Extracting features from batch 9901/17202 | ETA: 391.34 seconds\n",
      "Extracting features from batch 10001/17202 | ETA: 386.42 seconds\n",
      "Extracting features from batch 10101/17202 | ETA: 380.96 seconds\n",
      "Extracting features from batch 10201/17202 | ETA: 375.58 seconds\n",
      "Extracting features from batch 10301/17202 | ETA: 370.13 seconds\n",
      "Extracting features from batch 10401/17202 | ETA: 364.73 seconds\n",
      "Extracting features from batch 10501/17202 | ETA: 359.31 seconds\n",
      "Extracting features from batch 10601/17202 | ETA: 353.92 seconds\n",
      "Extracting features from batch 10701/17202 | ETA: 348.52 seconds\n",
      "Extracting features from batch 10801/17202 | ETA: 343.10 seconds\n",
      "Extracting features from batch 10901/17202 | ETA: 337.66 seconds\n",
      "Extracting features from batch 11001/17202 | ETA: 332.25 seconds\n",
      "Extracting features from batch 11101/17202 | ETA: 326.83 seconds\n",
      "Extracting features from batch 11201/17202 | ETA: 321.38 seconds\n",
      "Extracting features from batch 11301/17202 | ETA: 315.95 seconds\n",
      "Extracting features from batch 11401/17202 | ETA: 310.53 seconds\n",
      "Extracting features from batch 11501/17202 | ETA: 305.15 seconds\n",
      "Extracting features from batch 11601/17202 | ETA: 299.76 seconds\n",
      "Extracting features from batch 11701/17202 | ETA: 294.36 seconds\n",
      "Extracting features from batch 11801/17202 | ETA: 288.95 seconds\n",
      "Extracting features from batch 11901/17202 | ETA: 283.57 seconds\n",
      "Extracting features from batch 12001/17202 | ETA: 278.17 seconds\n",
      "Extracting features from batch 12101/17202 | ETA: 272.76 seconds\n",
      "Extracting features from batch 12201/17202 | ETA: 267.37 seconds\n",
      "Extracting features from batch 12301/17202 | ETA: 261.96 seconds\n",
      "Extracting features from batch 12401/17202 | ETA: 256.72 seconds\n",
      "Extracting features from batch 12501/17202 | ETA: 251.31 seconds\n",
      "Extracting features from batch 12601/17202 | ETA: 245.93 seconds\n",
      "Extracting features from batch 12701/17202 | ETA: 240.54 seconds\n",
      "Extracting features from batch 12801/17202 | ETA: 235.27 seconds\n",
      "Extracting features from batch 12901/17202 | ETA: 229.90 seconds\n",
      "Extracting features from batch 13001/17202 | ETA: 224.52 seconds\n",
      "Extracting features from batch 13101/17202 | ETA: 219.16 seconds\n",
      "Extracting features from batch 13201/17202 | ETA: 213.78 seconds\n",
      "Extracting features from batch 13301/17202 | ETA: 208.39 seconds\n",
      "Extracting features from batch 13401/17202 | ETA: 203.03 seconds\n",
      "Extracting features from batch 13501/17202 | ETA: 197.68 seconds\n",
      "Extracting features from batch 13601/17202 | ETA: 192.33 seconds\n",
      "Extracting features from batch 13701/17202 | ETA: 187.16 seconds\n",
      "Extracting features from batch 13801/17202 | ETA: 181.80 seconds\n",
      "Extracting features from batch 13901/17202 | ETA: 176.45 seconds\n",
      "Extracting features from batch 14001/17202 | ETA: 171.08 seconds\n",
      "Extracting features from batch 14101/17202 | ETA: 165.77 seconds\n",
      "Extracting features from batch 14201/17202 | ETA: 160.41 seconds\n",
      "Extracting features from batch 14301/17202 | ETA: 155.05 seconds\n",
      "Extracting features from batch 14401/17202 | ETA: 149.69 seconds\n",
      "Extracting features from batch 14501/17202 | ETA: 144.33 seconds\n",
      "Extracting features from batch 14601/17202 | ETA: 138.97 seconds\n",
      "Extracting features from batch 14701/17202 | ETA: 133.61 seconds\n",
      "Extracting features from batch 14801/17202 | ETA: 128.27 seconds\n",
      "Extracting features from batch 14901/17202 | ETA: 122.91 seconds\n",
      "Extracting features from batch 15001/17202 | ETA: 117.56 seconds\n",
      "Extracting features from batch 15101/17202 | ETA: 112.20 seconds\n",
      "Extracting features from batch 15201/17202 | ETA: 106.87 seconds\n",
      "Extracting features from batch 15301/17202 | ETA: 101.52 seconds\n",
      "Extracting features from batch 15401/17202 | ETA: 96.17 seconds\n",
      "Extracting features from batch 15501/17202 | ETA: 90.82 seconds\n",
      "Extracting features from batch 15601/17202 | ETA: 85.55 seconds\n",
      "Extracting features from batch 15701/17202 | ETA: 80.20 seconds\n",
      "Extracting features from batch 15801/17202 | ETA: 74.85 seconds\n",
      "Extracting features from batch 15901/17202 | ETA: 69.51 seconds\n",
      "Extracting features from batch 16001/17202 | ETA: 64.16 seconds\n",
      "Extracting features from batch 16101/17202 | ETA: 58.82 seconds\n",
      "Extracting features from batch 16201/17202 | ETA: 53.48 seconds\n",
      "Extracting features from batch 16301/17202 | ETA: 48.13 seconds\n",
      "Extracting features from batch 16401/17202 | ETA: 42.79 seconds\n",
      "Extracting features from batch 16501/17202 | ETA: 37.46 seconds\n",
      "Extracting features from batch 16601/17202 | ETA: 32.11 seconds\n",
      "Extracting features from batch 16701/17202 | ETA: 26.77 seconds\n",
      "Extracting features from batch 16801/17202 | ETA: 21.42 seconds\n",
      "Extracting features from batch 16901/17202 | ETA: 16.08 seconds\n",
      "Extracting features from batch 17001/17202 | ETA: 10.74 seconds\n",
      "Extracting features from batch 17101/17202 | ETA: 5.39 seconds\n",
      "Extracting features from batch 17201/17202 | ETA: 0.05 seconds\n",
      "Saving features to src/wesad/WESAD/manual_fe/wrist_manual_fe2.hdf5...\n",
      "Features saved successfully\n"
     ]
    }
   ],
   "source": [
    "from src.ml_pipeline.data_loader import DataAugmenter\n",
    "from src.ml_pipeline.feature_extraction import ManualFE\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "\n",
    "CHEST_CONFIG = 'config_files/dataset/wesad_chest_configuration.json'\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "\n",
    "wrist_augmenter = DataAugmenter('src/wesad/WESAD/cleaned/wrist_preprocessed.pkl', WRIST_CONFIG)\n",
    "batches = wrist_augmenter.segment_data(WINDOW_LENGTH, SLIDING_LENGTH)\n",
    "\n",
    "manual_fe = ManualFE(batches, 'src/wesad/WESAD/manual_fe/wrist_manual_fe2.hdf5', WRIST_CONFIG)\n",
    "manual_fe.extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import DataAugmenter\n",
    "from src.ml_pipeline.feature_extraction import ManualFE\n",
    "\n",
    "CHEST_CONFIG = 'config_files/dataset/wesad_chest_configuration.json'\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "\n",
    "chest_augmenter = DataAugmenter('src/wesad/WESAD/cleaned/chest_preprocessed.pkl', CHEST_CONFIG)\n",
    "batches = chest_augmenter.segment_data()\n",
    "\n",
    "manual_fe = ManualFE(batches, 'src/wesad/WESAD/manual_fe/chest_manual_fe.hdf5', CHEST_CONFIG)\n",
    "manual_fe.extract_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Machine Learning: Train and Validate Models with LOSOCV\n",
    "\n",
    "Now, using the preprocessed `.pkl` files we will make it into a dataloader - where LOSOCV (Leave one subject out cross validation). The data augmented samples will be used in the training set but ignored in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Train: 6205\n",
      "Val: 36\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TraditionalMLTrainer' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Example of predicting on validation data\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(val_loader)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Shutdown H2O cluster\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TraditionalMLTrainer' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "from src.ml_pipeline.data_loader import LOSOCVDataLoader\n",
    "from src.ml_pipeline.train import H2OTrainer, TraditionalMLTrainer\n",
    "\n",
    "# Set Parameters\n",
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "\n",
    "CHEST_CONFIG = 'config_files/dataset/wesad_chest_configuration.json'\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "\n",
    "losocv_loader = LOSOCVDataLoader('src/wesad/WESAD/manual_fe/wrist_manual_fe2.hdf5', WRIST_CONFIG, **params)\n",
    "dataloaders = losocv_loader.get_data_loaders()\n",
    "\n",
    "# Load tradtional model config\n",
    "TRADTIONAL_ML_CONFIG = 'config_files/model_training/traditional_models.json'\n",
    "\n",
    "results = []\n",
    "for i, (subject_id, loaders) in enumerate(dataloaders.items()):\n",
    "    train_loader = loaders['train']\n",
    "    val_loader = loaders['val']\n",
    "    \n",
    "    print(f'Fold {i}')\n",
    "    print(f'Train: {len(train_loader.dataset)}')\n",
    "    print(f'Val: {len(val_loader.dataset)}')\n",
    "    print()\n",
    "\n",
    "    # Initialize trainer\n",
    "    # trainer = H2OTrainer(TRADTIONAL_ML_CONFIG, train_loader, val_loader, 'label')\n",
    "    trainer = TraditionalMLTrainer(TRADTIONAL_ML_CONFIG, train_loader, val_loader)\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    result = trainer.validate()\n",
    "    print(result)\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Feature Extraction\n",
    "\n",
    "The automatic feature extraction uses autoencoders to derive features from its latent space:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Dev_C11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
