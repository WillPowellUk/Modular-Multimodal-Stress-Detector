{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Modular Multimodal Data Fusion ML Pipeline for stress detection for the WESAD Database\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started:\n",
    "First, download necessary packages, if you are using a venv such as Conda, activate this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Installation\n",
    "If you are on Linux, run this cell to download and extract the WESAD dataset automatically, otherwise download manually [here](https://uni-siegen.sciebo.de/s/HGdUkoNlW1Ub0Gx/download) and unzip the `WESAD` file into the `wesad` directory i.e. `wesad/WESAD/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd src/wesad && bash download_database.sh\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This will automatically extract the biosensor data from the WESAD directory into several merged files in `.pkl` format.\n",
    "\n",
    "This will take around 10 minutes depending on the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.wesad.data_preprocessing import WESADDataPreprocessor\n",
    "\n",
    "preprocessor = WESADDataPreprocessor('src/wesad/WESAD/')\n",
    "preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Preprocessing Steps\n",
    "We will preprocess each signal with their respective preprocessing steps:\n",
    "\n",
    "### Chest Signals\n",
    "\n",
    "#### ECG\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.7 Hz and 3.7 Hz.\n",
    "\n",
    "#### EMG\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth lowpass filter of order 3 with cutoff frequency 0.5 Hz.\n",
    "\n",
    "#### EDA\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth lowpass filter of order 2 with cutoff frequency 5 Hz.\n",
    "\n",
    "#### TEMP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "\n",
    "#### RESP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.1 Hz and 0.35 Hz.\n",
    "\n",
    "#### ACC\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 31 and order 5.\n",
    "\n",
    "### Wrist Signals\n",
    "\n",
    "#### BVP\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.7 Hz and 3.7 Hz.\n",
    "\n",
    "#### TEMP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "\n",
    "#### ACC\n",
    "- **Filtering**: Finite Impulse Response (FIR) filter with a length of 64 with a cut-off frequency of 0.4 Hz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config_files\n",
    "CHEST_CONFIG = 'config_files/dataset/wesad_chest_configuration.json'\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.preprocessing import SignalPreprocessor\n",
    "\n",
    "# preprocess the chest data\n",
    "signal_preprocessor = SignalPreprocessor('src/wesad/WESAD/raw/merged_chest.pkl', 'src/wesad/WESAD/cleaned/chest_preprocessed.pkl', CHEST_CONFIG)\n",
    "signal_preprocessor.preprocess_signals()\n",
    "\n",
    "# preprocess the wrist data\n",
    "signal_preprocessor = SignalPreprocessor('src/wesad/WESAD/raw/merged_wrist.pkl', 'src/wesad/WESAD/cleaned/wrist_preprocessed.pkl', WRIST_CONFIG, wrist=True)\n",
    "signal_preprocessor.preprocess_signals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation and Splitting\n",
    "Data augmentation will take the form of a sliding window. Once the data is augmented, each sample will then be split into smaller segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import DataAugmenter\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "\n",
    "wrist_augmenter = DataAugmenter('src/wesad/WESAD/cleaned/wrist_preprocessed.pkl', WRIST_CONFIG) \n",
    "batches = wrist_augmenter.augment_data(WINDOW_LENGTH, SLIDING_LENGTH)\n",
    "wrist_splitted_segments = wrist_augmenter.split_segments(batches, WINDOW_LENGTH//SPLIT_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Machine Learning\n",
    "\n",
    "The manual feature extraction derives features in the time, frequency and non-linear domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.feature_extraction import ManualFE\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "\n",
    "manual_fe = ManualFE(wrist_splitted_segments, WRIST_FE, WRIST_CONFIG)\n",
    "manual_fe.extract_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LOSOCV Datasets\n",
    "\n",
    "Now, using the preprocessed `.pkl` files we will make it into a dataloader with LOSOCV (Leave one subject out cross validation). The data augmented samples will be used in the training set but ignored in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import LOSOCVDataLoader\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "# WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/test203/wrist_manual_fe_{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s.hdf5'\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "losocv_loader = LOSOCVDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "\n",
    "# Prepare the datasets\n",
    "DATASETS_PATH = losocv_loader.prepare_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate Models with LOSOCV\n",
    "\n",
    "Now we can use the prepared datasets and form dataloaders which will then be used to perform LOSOCV on the models. Using the config file we can set the models that we want to test and their corresponding hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import LOSOCVDataLoader\n",
    "from src.ml_pipeline.train import TraditionalMLTrainer\n",
    "from src.utils import save_var\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "\n",
    "# Load tradtional model config\n",
    "losocv_loader = LOSOCVDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "dataloaders = losocv_loader.get_data_loaders(DATASETS_PATH)\n",
    "TRADTIONAL_ML_CONFIG = 'config_files/model_training/traditional/traditional_models.json'\n",
    "\n",
    "results = []\n",
    "for i, (subject_id, loaders) in enumerate(dataloaders.items()):\n",
    "    train_loader = loaders['train']\n",
    "    val_loader = loaders['val']\n",
    "    \n",
    "    print(f'Fold {i}')\n",
    "    print(f'Train: {len(train_loader.dataset)}')\n",
    "    print(f'Val: {len(val_loader.dataset)}')\n",
    "    print()\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = TraditionalMLTrainer(TRADTIONAL_ML_CONFIG, train_loader, val_loader)\n",
    "\n",
    "    # trained_models = trainer.tune_hyperparameters(n_jobs=4, cv=None, verbose=2)\n",
    "    trained_models = trainer.train()\n",
    "\n",
    "    result = trainer.validate(trained_models)\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "\n",
    "# save the results to pkl\n",
    "save_var(results, 'src/wesad/WESAD/results/traditional_models/wrist_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.analysis import ModelResultsAnalysis\n",
    "from src.utils import load_var\n",
    "\n",
    "results = load_var('src/wesad/WESAD/results/traditional_models/wrist_results.pkl')\n",
    "\n",
    "analysis = ModelResultsAnalysis(results)\n",
    "analysis.analyze_collective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention Network Alongside Manual Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LOSOCV Datasets on a Per Sensor Basis\n",
    "\n",
    "Now, using the preprocessed `.pkl` files we will make it into a dataloader with LOSOCV (Leave one subject out cross validation) on a per sensor basis. The data augmented samples will be used in the training set but ignored in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batches for subject 10 and label 1.0\n",
      "Processed batches for subject 10 and label 2.0\n",
      "Processed batches for subject 10 and label 1.0\n",
      "Processed batches for subject 10 and label 2.0\n",
      "Processed batches for subject 11 and label 1.0\n",
      "Processed batches for subject 11 and label 2.0\n",
      "Processed batches for subject 11 and label 1.0\n",
      "Processed batches for subject 11 and label 2.0\n",
      "Processed batches for subject 13 and label 1.0\n",
      "Processed batches for subject 13 and label 2.0\n",
      "Processed batches for subject 13 and label 1.0\n",
      "Processed batches for subject 13 and label 2.0\n",
      "Processed batches for subject 14 and label 1.0\n",
      "Processed batches for subject 14 and label 2.0\n",
      "Processed batches for subject 14 and label 1.0\n",
      "Processed batches for subject 14 and label 2.0\n",
      "Processed batches for subject 15 and label 1.0\n",
      "Processed batches for subject 15 and label 2.0\n",
      "Processed batches for subject 15 and label 1.0\n",
      "Processed batches for subject 15 and label 2.0\n",
      "Processed batches for subject 16 and label 1.0\n",
      "Processed batches for subject 16 and label 2.0\n",
      "Processed batches for subject 16 and label 1.0\n",
      "Processed batches for subject 16 and label 2.0\n",
      "Processed batches for subject 17 and label 1.0\n",
      "Processed batches for subject 17 and label 2.0\n",
      "Processed batches for subject 17 and label 1.0\n",
      "Processed batches for subject 17 and label 2.0\n",
      "Processed batches for subject 3 and label 1.0\n",
      "Processed batches for subject 3 and label 2.0\n",
      "Processed batches for subject 3 and label 1.0\n",
      "Processed batches for subject 3 and label 2.0\n",
      "Processed batches for subject 4 and label 1.0\n",
      "Processed batches for subject 4 and label 2.0\n",
      "Processed batches for subject 4 and label 1.0\n",
      "Processed batches for subject 4 and label 2.0\n",
      "Processed batches for subject 5 and label 1.0\n",
      "Processed batches for subject 5 and label 2.0\n",
      "Processed batches for subject 5 and label 1.0\n",
      "Processed batches for subject 5 and label 2.0\n",
      "Processed batches for subject 6 and label 1.0\n",
      "Processed batches for subject 6 and label 2.0\n",
      "Processed batches for subject 6 and label 1.0\n",
      "Processed batches for subject 6 and label 2.0\n",
      "Processed batches for subject 7 and label 1.0\n",
      "Processed batches for subject 7 and label 2.0\n",
      "Processed batches for subject 7 and label 1.0\n",
      "Processed batches for subject 7 and label 2.0\n",
      "Processed batches for subject 8 and label 1.0\n",
      "Processed batches for subject 8 and label 2.0\n",
      "Processed batches for subject 8 and label 1.0\n",
      "Processed batches for subject 8 and label 2.0\n",
      "Processed batches for subject 9 and label 1.0\n",
      "Processed batches for subject 9 and label 2.0\n",
      "Processed batches for subject 9 and label 1.0\n",
      "Processed batches for subject 9 and label 2.0\n",
      "Processed batches for subject 2 and label 1.0\n",
      "Processed batches for subject 2 and label 2.0\n",
      "Processed batches for subject 10 and label 1.0\n",
      "Processed batches for subject 10 and label 2.0\n",
      "Processed batches for subject 10 and label 1.0\n",
      "Processed batches for subject 10 and label 2.0\n",
      "Processed batches for subject 11 and label 1.0\n",
      "Processed batches for subject 11 and label 2.0\n",
      "Processed batches for subject 11 and label 1.0\n",
      "Processed batches for subject 11 and label 2.0\n",
      "Processed batches for subject 13 and label 1.0\n",
      "Processed batches for subject 13 and label 2.0\n",
      "Processed batches for subject 13 and label 1.0\n",
      "Processed batches for subject 13 and label 2.0\n",
      "Processed batches for subject 14 and label 1.0\n",
      "Processed batches for subject 14 and label 2.0\n",
      "Processed batches for subject 14 and label 1.0\n",
      "Processed batches for subject 14 and label 2.0\n",
      "Processed batches for subject 15 and label 1.0\n",
      "Processed batches for subject 15 and label 2.0\n",
      "Processed batches for subject 15 and label 1.0\n",
      "Processed batches for subject 15 and label 2.0\n",
      "Processed batches for subject 16 and label 1.0\n",
      "Processed batches for subject 16 and label 2.0\n",
      "Processed batches for subject 16 and label 1.0\n",
      "Processed batches for subject 16 and label 2.0\n",
      "Processed batches for subject 17 and label 1.0\n",
      "Processed batches for subject 17 and label 2.0\n",
      "Processed batches for subject 17 and label 1.0\n",
      "Processed batches for subject 17 and label 2.0\n",
      "Processed batches for subject 2 and label 1.0\n",
      "Processed batches for subject 2 and label 2.0\n",
      "Processed batches for subject 2 and label 1.0\n",
      "Processed batches for subject 2 and label 2.0\n",
      "Processed batches for subject 4 and label 1.0\n",
      "Processed batches for subject 4 and label 2.0\n",
      "Processed batches for subject 4 and label 1.0\n",
      "Processed batches for subject 4 and label 2.0\n",
      "Processed batches for subject 5 and label 1.0\n",
      "Processed batches for subject 5 and label 2.0\n",
      "Processed batches for subject 5 and label 1.0\n",
      "Processed batches for subject 5 and label 2.0\n",
      "Processed batches for subject 6 and label 1.0\n",
      "Processed batches for subject 6 and label 2.0\n",
      "Processed batches for subject 6 and label 1.0\n",
      "Processed batches for subject 6 and label 2.0\n",
      "Processed batches for subject 7 and label 1.0\n",
      "Processed batches for subject 7 and label 2.0\n",
      "Processed batches for subject 7 and label 1.0\n",
      "Processed batches for subject 7 and label 2.0\n",
      "Processed batches for subject 8 and label 1.0\n",
      "Processed batches for subject 8 and label 2.0\n",
      "Processed batches for subject 8 and label 1.0\n",
      "Processed batches for subject 8 and label 2.0\n",
      "Processed batches for subject 9 and label 1.0\n",
      "Processed batches for subject 9 and label 2.0\n",
      "Processed batches for subject 9 and label 1.0\n",
      "Processed batches for subject 9 and label 2.0\n",
      "Processed batches for subject 3 and label 1.0\n",
      "Processed batches for subject 3 and label 2.0\n",
      "Processed batches for subject 10 and label 1.0\n",
      "Processed batches for subject 10 and label 2.0\n",
      "Processed batches for subject 10 and label 1.0\n",
      "Processed batches for subject 10 and label 2.0\n",
      "Processed batches for subject 11 and label 1.0\n",
      "Processed batches for subject 11 and label 2.0\n",
      "Processed batches for subject 11 and label 1.0\n",
      "Processed batches for subject 11 and label 2.0\n",
      "Processed batches for subject 13 and label 1.0\n",
      "Processed batches for subject 13 and label 2.0\n",
      "Processed batches for subject 13 and label 1.0\n",
      "Processed batches for subject 13 and label 2.0\n",
      "Processed batches for subject 14 and label 1.0\n",
      "Processed batches for subject 14 and label 2.0\n",
      "Processed batches for subject 14 and label 1.0\n",
      "Processed batches for subject 14 and label 2.0\n",
      "Processed batches for subject 15 and label 1.0\n",
      "Processed batches for subject 15 and label 2.0\n",
      "Processed batches for subject 15 and label 1.0\n",
      "Processed batches for subject 15 and label 2.0\n",
      "Processed batches for subject 16 and label 1.0\n",
      "Processed batches for subject 16 and label 2.0\n",
      "Processed batches for subject 16 and label 1.0\n",
      "Processed batches for subject 16 and label 2.0\n",
      "Processed batches for subject 17 and label 1.0\n",
      "Processed batches for subject 17 and label 2.0\n",
      "Processed batches for subject 17 and label 1.0\n",
      "Processed batches for subject 17 and label 2.0\n",
      "Processed batches for subject 2 and label 1.0\n",
      "Processed batches for subject 2 and label 2.0\n",
      "Processed batches for subject 2 and label 1.0\n",
      "Processed batches for subject 2 and label 2.0\n",
      "Processed batches for subject 3 and label 1.0\n",
      "Processed batches for subject 3 and label 2.0\n",
      "Processed batches for subject 3 and label 1.0\n",
      "Processed batches for subject 3 and label 2.0\n",
      "Processed batches for subject 5 and label 1.0\n",
      "Processed batches for subject 5 and label 2.0\n",
      "Processed batches for subject 5 and label 1.0\n",
      "Processed batches for subject 5 and label 2.0\n",
      "Processed batches for subject 6 and label 1.0\n",
      "Processed batches for subject 6 and label 2.0\n",
      "Processed batches for subject 6 and label 1.0\n",
      "Processed batches for subject 6 and label 2.0\n",
      "Processed batches for subject 7 and label 1.0\n",
      "Processed batches for subject 7 and label 2.0\n",
      "Processed batches for subject 7 and label 1.0\n",
      "Processed batches for subject 7 and label 2.0\n",
      "Processed batches for subject 8 and label 1.0\n",
      "Processed batches for subject 8 and label 2.0\n",
      "Processed batches for subject 8 and label 1.0\n",
      "Processed batches for subject 8 and label 2.0\n",
      "Processed batches for subject 9 and label 1.0\n",
      "Processed batches for subject 9 and label 2.0\n"
     ]
    }
   ],
   "source": [
    "from src.ml_pipeline.data_loader import LOSOCVSensorDataLoader\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/wrist_features.hdf5'\n",
    "dataloader_params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "losocv_loader = LOSOCVSensorDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "\n",
    "# Prepare the datasets\n",
    "DATASETS_PATH = losocv_loader.prepare_datasets(f'src/wesad/WESAD/datasets/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate Models with LOSOCV\n",
    "\n",
    "Now we can use the prepared datasets and form dataloaders which will then be used to perform LOSOCV on the models. Using the config file we can set the models that we want to test and their corresponding hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.train import PyTorchTrainer\n",
    "from src.ml_pipeline.models.san import ModularModalityFusionNet\n",
    "from src.ml_pipeline.data_loader import LOSOCVSensorDataLoader\n",
    "from src.ml_pipeline.utils import get_active_key, get_key, copy_json\n",
    "from src.utils import save_var\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "\n",
    "DATASETS_PATH = f'src/wesad/WESAD/datasets/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}_mini/wrist_manual_fe_{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}.hdf5'\n",
    "WRIST_CONFIG = 'config_files/dataset/wesad_wrist_configuration.json'\n",
    "WRIST_FE = f'src/wesad/WESAD/manual_fe/wrist_manual_fe/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s_mini/wrist_features.hdf5'\n",
    "SAN_MODEL_CONFIG = 'config_files/model_training/deep/san_config.json'\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "\n",
    "# Load Dataloaders for LOSOCV\n",
    "losocv_loader = LOSOCVSensorDataLoader(WRIST_FE, WRIST_CONFIG, **dataloader_params)\n",
    "dataloaders, input_dims = losocv_loader.get_data_loaders(DATASETS_PATH)\n",
    "\n",
    "# Load Model Parameters\n",
    "num_classes = len(get_active_key(WRIST_CONFIG, 'labels'))\n",
    "embed_dim = get_key(SAN_MODEL_CONFIG, 'EMBED_DIM')\n",
    "hidden_dim = get_key(SAN_MODEL_CONFIG, 'HIDDEN_DIM')\n",
    "n_head_gen = get_key(SAN_MODEL_CONFIG, 'N_HEAD_GEN')\n",
    "n_head_per = get_key(SAN_MODEL_CONFIG, 'N_HEAD_PER')\n",
    "\n",
    "results = []\n",
    "for i, (subject_id, loaders) in enumerate(dataloaders.items()):\n",
    "    train_loader = loaders['train']\n",
    "    val_loader = loaders['val']\n",
    "    \n",
    "    print(f'Fold {i}')\n",
    "    print(f'Train: {len(train_loader.dataset)}')\n",
    "    print(f'Val: {len(val_loader.dataset)}')\n",
    "    print()\n",
    "\n",
    "    # Initialize model\n",
    "    model = ModularModalityFusionNet(input_dims=input_dims, embed_dim=embed_dim, hidden_dim=hidden_dim, output_dim=num_classes)\n",
    "\n",
    "    # Initialize trainer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'Using device: {device}')\n",
    "    trainer = PyTorchTrainer(model, train_loader, val_loader, SAN_MODEL_CONFIG, device)\n",
    "    trained_model_ckpt = trainer.train()\n",
    "\n",
    "    result = trainer.validate(trained_model_ckpt)\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "\n",
    "# save the results to pkl\n",
    "current_time = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "save_path = 'src/wesad/WESAD/results/SAN/wrist_results/{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s/{current_time}/'\n",
    "save_var(results, f'{save_path}.pkl')\n",
    "copy_json(SAN_MODEL_CONFIG, f'{save_path}_config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.analysis import ModelResultsAnalysis\n",
    "from src.utils import load_var\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "SPLIT_LENGTH = 10 # this will split each 60 second segments into 6 x 10 second segments\n",
    "\n",
    "results = load_var('src/wesad/WESAD/results/SAN/wrist_results_{WINDOW_LENGTH}s_{SLIDING_LENGTH}s_{SPLIT_LENGTH}s.pkl')\n",
    "\n",
    "analysis = ModelResultsAnalysis(results)\n",
    "analysis.analyze_collective()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Dev_C11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
