{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Modular Multimodal Data Fusion ML Pipeline for stress detection for the WESAD Database\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started:\n",
    "First, download necessary packages, if you are using a venv such as Conda, activate this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Installation\n",
    "If you are on Linux, run this cell to download and extract the WESAD dataset automatically, otherwise download manually [here](https://uni-siegen.sciebo.de/s/HGdUkoNlW1Ub0Gx/download) and unzip the `WESAD` file into the `wesad` directory i.e. `wesad/WESAD/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd src/wesad && bash download_database.sh\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This will automatically extract the biosensor data from the WESAD directory into several merged files in `.pkl` format.\n",
    "\n",
    "This will take around 10 minutes depending on the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.wesad.data_preprocessing import WESADDataPreprocessor\n",
    "\n",
    "preprocessor = WESADDataPreprocessor('src/wesad/WESAD/')\n",
    "preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Preprocessing Steps\n",
    "We will preprocess each signal with their respective preprocessing steps:\n",
    "\n",
    "### Chest Signals\n",
    "\n",
    "#### ECG\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.7 Hz and 3.7 Hz.\n",
    "\n",
    "#### EMG\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth lowpass filter of order 3 with cutoff frequency 0.5 Hz.\n",
    "\n",
    "#### EDA\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth lowpass filter of order 2 with cutoff frequency 5 Hz.\n",
    "\n",
    "#### TEMP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "\n",
    "#### RESP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.1 Hz and 0.35 Hz.\n",
    "\n",
    "#### ACC\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 31 and order 5.\n",
    "\n",
    "### Wrist Signals\n",
    "\n",
    "#### BVP\n",
    "- **Filtering**: Butterworth band-pass filter of order 3 with cutoff frequencies 0.7 Hz and 3.7 Hz.\n",
    "\n",
    "#### TEMP\n",
    "- **Smoothing**: Savitzky–Golay filter with window size 11 and order 3.\n",
    "\n",
    "#### ACC\n",
    "- **Filtering**: Finite Impulse Response (FIR) filter with a length of 64 with a cut-off frequency of 0.4 Hz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config_files\n",
    "CHEST_CONFIG = 'src/wesad/wesad_chest_configuration.json'\n",
    "WRIST_CONFIG = 'src/wesad/wesad_wrist_configuration.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.preprocessing import SignalPreprocessor\n",
    "\n",
    "# preprocess the chest data\n",
    "signal_preprocessor = SignalPreprocessor('src/wesad/WESAD/raw/merged_chest.pkl', 'src/wesad/WESAD/cleaned/chest_preprocessed.pkl', CHEST_CONFIG)\n",
    "signal_preprocessor.preprocess_signals()\n",
    "\n",
    "# preprocess the wrist data\n",
    "signal_preprocessor = SignalPreprocessor('src/wesad/WESAD/raw/merged_wrist.pkl', 'src/wesad/WESAD/cleaned/wrist_preprocessed.pkl', WRIST_CONFIG, wrist=True)\n",
    "signal_preprocessor.preprocess_signals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Machine Learning: Manual Feature Extraction\n",
    "\n",
    "During the feature extraction, data is loaded in an augmented manner using a 60-second window with a sliding length of 5 seconds.\n",
    "\n",
    "The manual feature extraction derives the following features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import DataAugmenter\n",
    "from src.ml_pipeline.feature_extraction import ManualFE\n",
    "\n",
    "WINDOW_LENGTH = 60\n",
    "SLIDING_LENGTH = 5\n",
    "\n",
    "CHEST_CONFIG = 'src/wesad/wesad_chest_configuration.json'\n",
    "WRIST_CONFIG = 'src/wesad/wesad_wrist_configuration.json'\n",
    "\n",
    "wrist_augmenter = DataAugmenter('src/wesad/WESAD/cleaned/wrist_preprocessed.pkl', WRIST_CONFIG)\n",
    "batches = wrist_augmenter.segment_data(WINDOW_LENGTH, SLIDING_LENGTH)\n",
    "\n",
    "manual_fe = ManualFE(batches, 'src/wesad/WESAD/manual_fe/wrist_manual_fe.hdf5', WRIST_CONFIG)\n",
    "manual_fe.extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.data_loader import DataAugmenter\n",
    "from src.ml_pipeline.feature_extraction import ManualFE\n",
    "\n",
    "chest_augmenter = DataAugmenter('src/wesad/WESAD/cleaned/chest_preprocessed.pkl', CHEST_CONFIG)\n",
    "batches = chest_augmenter.segment_data()\n",
    "\n",
    "manual_fe = ManualFE(batches, 'src/wesad/WESAD/manual_fe/chest_manual_fe.hdf5', CHEST_CONFIG)\n",
    "manual_fe.extract_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Machine Learning: Automatic Feature Extraction\n",
    "\n",
    "The automatic feature extraction uses autoencoders to derive features from its latent space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the preprocessed `.pkl` files we will make it into a dataloader - where LOSOCV (Leave one subject out cross validation). The data augmented samples will be used in the training set but ignored in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Not augmented found!\n",
      "Fold 0\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 1\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 2\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 3\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 4\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 5\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 6\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 7\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 8\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 9\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 10\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 11\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 12\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 13\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n",
      "Fold 14\n",
      "Train: 1944\n",
      "Val: 162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.ml_pipeline.data_loader import LOSOCVDataLoader\n",
    "\n",
    "# Set Parameters\n",
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    # 'num_workers': 4\n",
    "}\n",
    "\n",
    "CHEST_CONFIG = 'src/wesad/wesad_chest_configuration.json'\n",
    "WRIST_CONFIG = 'src/wesad/wesad_wrist_configuration.json'\n",
    "\n",
    "losocv_loader = LOSOCVDataLoader('src/wesad/WESAD/manual_fe/wrist_manual_fe.hdf5', WRIST_CONFIG, **params)\n",
    "dataloaders = losocv_loader.get_dataloaders()\n",
    "\n",
    "for i, (subject_id, loaders) in enumerate(dataloaders.items()):\n",
    "    train_loader = loaders['train']\n",
    "    val_loader = loaders['val']\n",
    "    \n",
    "    print(f'Fold {i}')\n",
    "    print(f'Train: {len(train_loader.dataset)}')\n",
    "    print(f'Val: {len(val_loader.dataset)}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('src/wesad/WESAD/raw/merged_chest.pkl')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_pickle('src/wesad/WESAD/raw/merged_wrist.pkl')\n",
    "df = pd.read_pickle('/home/fsociety/WESAD/S2/S2.pkl')\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['w_acc_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('src/wesad/WESAD/cleaned/chest_preprocessed.pkl')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_pickle('src/wesad/WESAD/cleaned/chest_preprocessed.pkl')\n",
    "\n",
    "df = pd.read_pickle('src/wesad/WESAD/augmented/chest_augmented.pkl')\n",
    "\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('src/wesad/WESAD/raw/merged_wrist.pkl')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "pkl_path1 = 'wesad/WESAD/raw/subj_merged_acc_w.pkl'\n",
    "pkl_path2 = 'wesad/WESAD/raw/subj_merged_eda_temp_w.pkl'\n",
    "pkl_path3 = 'wesad/WESAD/raw/subj_merged_bvp_w.pkl'\n",
    "\n",
    "# Load the data from pickle files\n",
    "df1 = pd.read_pickle(pkl_path1)\n",
    "df2 = pd.read_pickle(pkl_path2)\n",
    "df3 = pd.read_pickle(pkl_path3)\n",
    "\n",
    "# Merge dataframes on common columns (assumed to be a common index)\n",
    "# Adjust the merge method and key columns as needed\n",
    "merged_df = df1.merge(df2, left_index=True, right_index=True, how='inner')\n",
    "merged_df = merged_df.merge(df3, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Save the merged dataframe to a new pickle file\n",
    "merged_df.to_pickle('wesad/WESAD/raw/merged_wrist.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Dev_C11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
